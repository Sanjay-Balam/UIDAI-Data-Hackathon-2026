{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfdb\ufe0f Aadhaar Pulse 2.0\n",
        "## Unlocking Societal Trends in Aadhaar Enrolment and Updates\n",
        "\n",
        "---\n",
        "\n",
        "### UIDAI Data Hackathon 2026\n",
        "\n",
        "---\n",
        "\n",
        "## Executive Summary\n",
        "\n",
        "**Aadhaar Pulse 2.0** treats India's identity ecosystem as a living sensor of socio-economic dynamics. By analyzing enrolment and update patterns across **10 months** and **36 states**, we derive actionable intelligence for:\n",
        "\n",
        "1. **Service Optimization** - Identifying overloaded service centers (WHERE to open new centers)\n",
        "2. **Child Welfare Protection** - Detecting compliance gaps in mandatory biometric updates (WHICH children are at risk)\n",
        "3. **Resource Allocation** - Predicting seasonal demand patterns (WHEN to deploy resources)\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "| Metric | Finding |\n",
        "|--------|--------|\n",
        "| **5M+** | Total records processed |\n",
        "| **36** | States/UTs covered |\n",
        "| **Delhi** | Most stressed region (59K+ transactions/PIN) |\n",
        "| **Gujarat** | Highest child compliance risk (4 of top 5 at-risk districts) |\n",
        "| **June-Aug** | \"School Rush\" - 40% demand spike detected |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. Problem Statement\n",
        "\n",
        "> **\"Identify meaningful patterns, trends, anomalies, or predictive indicators and translate them into clear insights or solution frameworks that can support informed decision-making and system improvements.\"**\n",
        "\n",
        "### Our Interpretation: Three Critical Questions\n",
        "\n",
        "| Question | Current Gap | Our Solution |\n",
        "|----------|-------------|-------------|\n",
        "| **WHERE** should UIDAI open new centers? | Know center locations, not if overloaded | Service Pressure Score (SPS) |\n",
        "| **WHICH** children are at risk of ID deactivation? | No district-level risk visibility | Child Compliance Z-Score |\n",
        "| **WHEN** should resources be deployed? | Static allocation year-round | Seasonality Detection |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 2. Datasets Used\n",
        "\n",
        "| Dataset | Records | Columns | Description |\n",
        "|---------|---------|---------|-------------|\n",
        "| **Enrolment** | 1,006,029 | date, state, district, pincode, age_0_5, age_5_17, age_18_greater | New Aadhaar registrations by age group |\n",
        "| **Demographic Updates** | 2,071,700 | date, state, district, pincode, demo_age_5_17, demo_age_17_ | Address/name/DOB changes |\n",
        "| **Biometric Updates** | 1,861,108 | date, state, district, pincode, bio_age_5_17, bio_age_17_ | Fingerprint/iris/face updates |\n",
        "\n",
        "**Date Range:** March 2025 - December 2025 (10 months)\n",
        "\n",
        "**Total Records:** ~5 Million transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import os\n",
        "import glob\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Display settings\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
        "\n",
        "# Base path - UPDATE THIS FOR YOUR SYSTEM\n",
        "BASE_PATH = \"/Users/balamsanjay/Desktop/UDIAI-DataHackthon/\"\n",
        "\n",
        "print(\"\u2705 Libraries loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Raw Datasets\n",
        "def load_dataset(folder_name):\n",
        "    folder_path = os.path.join(BASE_PATH, folder_name)\n",
        "    all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
        "    dfs = [pd.read_csv(f) for f in all_files]\n",
        "    return pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "print(\"\ud83d\udcca Loading datasets...\")\n",
        "enrol_df = load_dataset('api_data_aadhar_enrolment')\n",
        "bio_df = load_dataset('api_data_aadhar_biometric')\n",
        "demo_df = load_dataset('api_data_aadhar_demographic')\n",
        "\n",
        "print(f\"\\n\ud83d\udcc8 Dataset Summary:\")\n",
        "print(f\"   Enrolment:   {len(enrol_df):>10,} records\")\n",
        "print(f\"   Biometric:   {len(bio_df):>10,} records\")\n",
        "print(f\"   Demographic: {len(demo_df):>10,} records\")\n",
        "print(f\"   TOTAL:       {len(enrol_df)+len(bio_df)+len(demo_df):>10,} records\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show sample data\n",
        "print(\"\ud83d\udccb Enrolment Dataset Sample:\")\n",
        "display(enrol_df.head(3))\n",
        "print(\"\\n\ud83d\udccb Biometric Dataset Sample:\")\n",
        "display(bio_df.head(3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 3. Methodology\n",
        "\n",
        "### 3.1 Data Cleaning\n",
        "\n",
        "**Challenges:**\n",
        "1. State name variations (50+ variations \u2192 36 official names)\n",
        "2. District duplicates (Bengaluru/Bangalore)\n",
        "3. Garbage data (\"100000\", \"?\" as district names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Cleaning\n",
        "def normalize_state_names(df):\n",
        "    if 'state' not in df.columns: return df\n",
        "    df['state'] = df['state'].astype(str).str.strip().str.title()\n",
        "    state_map = {\n",
        "        'Andaman And Nicobar Islands': 'Andaman & Nicobar Islands',\n",
        "        'Nct Of Delhi': 'Delhi', 'Delhi Nct': 'Delhi',\n",
        "        'Orissa': 'Odisha', 'Pondicherry': 'Puducherry',\n",
        "    }\n",
        "    df['state'] = df['state'].map(lambda x: state_map.get(x, x))\n",
        "    return df\n",
        "\n",
        "def normalize_district_names(df):\n",
        "    if 'district' not in df.columns: return df\n",
        "    df = df.dropna(subset=['district'])\n",
        "    df['district'] = df['district'].astype(str).str.strip().str.title()\n",
        "    mask = df['district'].str.contains(r'[a-zA-Z]') & (df['district'].str.len() > 2)\n",
        "    return df[mask]\n",
        "\n",
        "# Apply cleaning\n",
        "print(\"\ud83e\uddf9 Cleaning data...\")\n",
        "for df in [enrol_df, bio_df, demo_df]:\n",
        "    df = normalize_state_names(df)\n",
        "    df = normalize_district_names(df)\n",
        "\n",
        "enrol_df = normalize_state_names(enrol_df)\n",
        "enrol_df = normalize_district_names(enrol_df)\n",
        "bio_df = normalize_state_names(bio_df)\n",
        "bio_df = normalize_district_names(bio_df)\n",
        "demo_df = normalize_state_names(demo_df)\n",
        "demo_df = normalize_district_names(demo_df)\n",
        "\n",
        "print(f\"\u2705 Unique States: {enrol_df['state'].nunique()}\")\n",
        "print(f\"\u2705 Unique Districts: {enrol_df['district'].nunique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 4. Data Analysis\n",
        "\n",
        "### 4.1 Pillar 1: Service Accessibility Index (SAI)\n",
        "\n",
        "**Formula:** `SPS = Total Transactions / Active PIN Codes`\n",
        "\n",
        "**Interpretation:** High SPS = Service bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate Service Pressure Score\n",
        "print(\"\ud83d\udcca Calculating Service Pressure Score...\")\n",
        "\n",
        "enrol_vol = enrol_df.groupby('district')[['age_0_5', 'age_5_17', 'age_18_greater']].sum().sum(axis=1)\n",
        "bio_vol = bio_df.groupby('district')[['bio_age_5_17', 'bio_age_17_']].sum().sum(axis=1)\n",
        "demo_vol = demo_df.groupby('district')[['demo_age_5_17', 'demo_age_17_']].sum().sum(axis=1)\n",
        "\n",
        "total_volume = enrol_vol.add(bio_vol, fill_value=0).add(demo_vol, fill_value=0)\n",
        "unique_pins = enrol_df.groupby('district')['pincode'].nunique()\n",
        "sps_score = total_volume / unique_pins.replace(0, 1)\n",
        "\n",
        "district_df = pd.DataFrame({\n",
        "    'district': total_volume.index,\n",
        "    'total_volume': total_volume.values,\n",
        "    'unique_pincodes': unique_pins.reindex(total_volume.index).fillna(1).values,\n",
        "    'sps_score': sps_score.values\n",
        "})\n",
        "state_map = enrol_df.groupby('district')['state'].first()\n",
        "district_df['state'] = district_df['district'].map(state_map)\n",
        "\n",
        "print(\"\\n\ud83d\udd34 TOP 10 DISTRICTS BY SERVICE PRESSURE:\")\n",
        "for _, row in district_df.nlargest(10, 'sps_score').iterrows():\n",
        "    print(f\"   {row['district']:30} SPS: {row['sps_score']:,.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize SAI\n",
        "top_pressure = district_df.nlargest(20, 'sps_score')\n",
        "\n",
        "fig_sps = px.bar(\n",
        "    top_pressure, x='district', y='sps_score', color='state',\n",
        "    title='<b>Top 20 Districts by Service Pressure Score</b>',\n",
        "    labels={'sps_score': 'Service Pressure Score', 'district': 'District'},\n",
        "    template='plotly_white'\n",
        ")\n",
        "fig_sps.update_layout(xaxis_tickangle=-45, height=500)\n",
        "fig_sps.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Pillar 2: Child Lifecycle Compliance Score (CLCS)\n",
        "\n",
        "**Formula:** `Z-Score = (District Compliance - National Mean) / Std Dev`\n",
        "\n",
        "**Interpretation:** Z < -1.5 = HIGH RISK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate CLCS\n",
        "print(\"\ud83d\udcca Calculating Child Compliance Z-Score...\")\n",
        "\n",
        "child_bio = bio_df.groupby('district')['bio_age_5_17'].sum()\n",
        "child_enrol = enrol_df.groupby('district')[['age_0_5', 'age_5_17']].sum().sum(axis=1)\n",
        "total_child = child_bio.add(child_enrol, fill_value=0)\n",
        "compliance_share = child_bio / total_child.replace(0, 1)\n",
        "\n",
        "national_mean = compliance_share.mean()\n",
        "national_std = compliance_share.std()\n",
        "clcs_zscore = (compliance_share - national_mean) / national_std\n",
        "\n",
        "district_df['total_child_activity'] = district_df['district'].map(total_child).fillna(0)\n",
        "district_df['clcs_zscore'] = district_df['district'].map(clcs_zscore).fillna(0)\n",
        "\n",
        "print(\"\\n\u26a0\ufe0f TOP 10 AT-RISK DISTRICTS:\")\n",
        "at_risk = district_df[district_df['total_child_activity'] > 1000].nsmallest(10, 'clcs_zscore')\n",
        "for _, row in at_risk.iterrows():\n",
        "    print(f\"   {row['district']:30} Z: {row['clcs_zscore']:+.2f}\u03c3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize CLCS Risk\n",
        "active = district_df[district_df['total_child_activity'] > 1000]\n",
        "\n",
        "fig_risk = px.scatter(\n",
        "    active, x='total_child_activity', y='clcs_zscore', color='state',\n",
        "    size='total_volume', hover_name='district',\n",
        "    title='<b>Child Compliance Risk Map</b>',\n",
        "    labels={'clcs_zscore': 'Z-Score', 'total_child_activity': 'Child Activity'},\n",
        "    template='plotly_white', height=600\n",
        ")\n",
        "fig_risk.add_hline(y=-1.5, line_dash=\"dash\", line_color=\"red\", annotation_text=\"HIGH RISK\")\n",
        "fig_risk.add_hline(y=0, line_dash=\"dot\", line_color=\"gray\")\n",
        "fig_risk.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Pillar 3: Seasonality Detection (DIH)\n",
        "\n",
        "Analyzing monthly patterns to detect **School Rush** (June-Aug)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seasonality Analysis\n",
        "enrol_df['date'] = pd.to_datetime(enrol_df['date'], format='%d-%m-%Y', errors='coerce')\n",
        "enrol_df['month'] = enrol_df['date'].dt.month\n",
        "\n",
        "monthly = enrol_df.groupby('month')[['age_0_5', 'age_5_17', 'age_18_greater']].sum()\n",
        "monthly['total'] = monthly.sum(axis=1)\n",
        "monthly['season'] = monthly.index.map(lambda m: 'School Rush' if m in [6,7,8] else 'Normal')\n",
        "monthly = monthly.reset_index()\n",
        "\n",
        "fig_season = px.bar(\n",
        "    monthly, x='month', y='total', color='season',\n",
        "    title='<b>Monthly Volume with Seasonality</b>',\n",
        "    template='plotly_white',\n",
        "    color_discrete_map={'School Rush': 'red', 'Normal': 'blue'}\n",
        ")\n",
        "fig_season.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 5. Summary & Recommendations\n",
        "\n",
        "| Finding | Impact | Recommendation |\n",
        "|---------|--------|----------------|\n",
        "| Delhi: 30K-59K transactions/PIN | Service bottleneck | Open 5+ new centers |\n",
        "| Gujarat: 4 of top 5 at-risk | Child welfare crisis | School Aadhaar Camps |\n",
        "| June-Aug: School Rush | Demand spike | Pre-deploy in May |\n",
        "\n",
        "---\n",
        "\n",
        "## Thank You!\n",
        "\n",
        "*\"Aadhaar Pulse 2.0 - Turning data into actionable intelligence for a more inclusive India.\"*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}